[Fri Jan 06 10:10:49 2023|run.py|INFO] <models.CNN.Config object at 0x000002658E3F7F70>
[Fri Jan 06 10:10:49 2023|run.py|INFO] Namespace(model='CNN', save_path='./datasets/CHIP-CTC/data/out.npz')
[Fri Jan 06 10:10:50 2023|modeling.py|INFO] loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz from cache at C:\Users\Lenovo\.pytorch_pretrained_bert\42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f
[Fri Jan 06 10:10:50 2023|modeling.py|INFO] extracting archive file C:\Users\Lenovo\.pytorch_pretrained_bert\42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f to temp dir C:\Users\Lenovo\AppData\Local\Temp\tmptq23tj9p
[Fri Jan 06 10:10:54 2023|modeling.py|INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[Fri Jan 06 10:10:58 2023|modeling.py|INFO] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
[Fri Jan 06 10:10:58 2023|train_eval.py|INFO] Epoch [1/3]
[Fri Jan 06 10:23:23 2023|train_eval.py|INFO] Iter:      0,  Val P: 0.005191,  Val R: 2.0578%,  Val F1: 0.000843,  Val Acc: 0.3385%,  Time: 0:12:25 *
[Fri Jan 06 11:13:35 2023|train_eval.py|INFO] Iter:    300,  Val P: 0.5761,  Val R: 45.9730%,  Val F1: 0.4658,  Val Acc: 76.5816%,  Time: 1:02:37 *
[Fri Jan 06 11:59:40 2023|train_eval.py|INFO] Iter:    600,  Val P: 0.7308,  Val R: 60.7424%,  Val F1: 0.6436,  Val Acc: 80.0833%,  Time: 1:48:42 *
[Fri Jan 06 12:34:25 2023|train_eval.py|INFO] Epoch [2/3]
[Fri Jan 06 12:46:09 2023|train_eval.py|INFO] Iter:    900,  Val P: 0.721,  Val R: 70.0448%,  Val F1: 0.6824,  Val Acc: 81.2158%,  Time: 2:35:11 *
[Fri Jan 06 13:32:36 2023|train_eval.py|INFO] Iter:   1200,  Val P: 0.7893,  Val R: 68.8727%,  Val F1: 0.7064,  Val Acc: 82.6868%,  Time: 3:21:38 *
[Fri Jan 06 14:24:33 2023|train_eval.py|INFO] Iter:   1500,  Val P: 0.7843,  Val R: 71.9828%,  Val F1: 0.7352,  Val Acc: 83.0513%,  Time: 4:13:36 *
[Fri Jan 06 15:04:40 2023|train_eval.py|INFO] Epoch [3/3]
[Fri Jan 06 15:21:17 2023|train_eval.py|INFO] Iter:   1800,  Val P: 0.8263,  Val R: 82.3544%,  Val F1: 0.8192,  Val Acc: 83.9625%,  Time: 5:10:19 *
[Sat Jan 14 10:52:20 2023|run.py|INFO] <models.CNN.Config object at 0x000001A114E37F70>
[Sat Jan 14 10:52:20 2023|run.py|INFO] Namespace(model='CNN', save_path='./datasets/CHIP-CTC/data/out.npz')
[Sat Jan 14 10:52:21 2023|modeling.py|INFO] loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz from cache at C:\Users\Lenovo\.pytorch_pretrained_bert\42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f
[Sat Jan 14 10:52:21 2023|modeling.py|INFO] extracting archive file C:\Users\Lenovo\.pytorch_pretrained_bert\42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f to temp dir C:\Users\Lenovo\AppData\Local\Temp\tmpj5rjaa91
[Sat Jan 14 10:52:26 2023|modeling.py|INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[Sat Jan 14 10:52:30 2023|modeling.py|INFO] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
[Sat Jan 14 10:52:30 2023|train_eval.py|INFO] Epoch [1/3]
[Sat Jan 14 11:05:20 2023|train_eval.py|INFO] Iter:      0,  Val P: 0.005191,  Val R: 2.0578%,  Val F1: 0.000843,  Val Acc: 0.3385%,  Time: 0:12:50 *
[Sat Jan 14 11:40:09 2023|modeling.py|INFO] loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz from cache at C:\Users\Lenovo\.pytorch_pretrained_bert\42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f
[Sat Jan 14 11:40:09 2023|modeling.py|INFO] extracting archive file C:\Users\Lenovo\.pytorch_pretrained_bert\42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f to temp dir C:\Users\Lenovo\AppData\Local\Temp\tmpxsh_sbks
[Sat Jan 14 11:40:13 2023|modeling.py|INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[Sat Jan 14 15:44:59 2023|run.py|INFO] <models.CNN.Config object at 0x0000018EC3D67F70>
[Sat Jan 14 15:44:59 2023|run.py|INFO] Namespace(model='CNN', save_path='./datasets/CHIP-CTC/data/out.npz')
[Sat Jan 14 15:45:00 2023|modeling.py|INFO] loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz from cache at C:\Users\Lenovo\.pytorch_pretrained_bert\42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f
[Sat Jan 14 15:45:00 2023|modeling.py|INFO] extracting archive file C:\Users\Lenovo\.pytorch_pretrained_bert\42d4a64dda3243ffeca7ec268d5544122e67d9d06b971608796b483925716512.02ac7d664cff08d793eb00d6aac1d04368a1322435e5fe0a27c70b0b3a85327f to temp dir C:\Users\Lenovo\AppData\Local\Temp\tmptuyu82ht
[Sat Jan 14 15:45:03 2023|modeling.py|INFO] Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

[Sat Jan 14 15:45:06 2023|modeling.py|INFO] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
[Sat Jan 14 15:45:06 2023|train_eval.py|INFO] Epoch [1/3]
